{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credits\n",
    "\n",
    "This is heavily influenced by https://github.com/pytorch/tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtext\n",
      "  Downloading https://files.pythonhosted.org/packages/78/90/474d5944d43001a6e72b9aaed5c3e4f77516fbef2317002da2096fd8b5ea/torchtext-0.2.3.tar.gz (42kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 2.2MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting nltk\n",
      "  Downloading https://files.pythonhosted.org/packages/50/09/3b1755d528ad9156ee7243d52aa5cd2b809ef053a0f31b53d92853dd653a/nltk-3.3.0.zip (1.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.4MB 937kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting tqdm (from torchtext)\n",
      "  Downloading https://files.pythonhosted.org/packages/79/43/19c9fee28110cd47f73e6bc596394337fe9f3e5825b4de402bbf30b3beb5/tqdm-4.26.0-py2.py3-none-any.whl (43kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 5.8MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting requests (from torchtext)\n",
      "  Downloading https://files.pythonhosted.org/packages/65/47/7e02164a2a3db50ed6d8a6ab1d6d60b69c4c3fdf57a284257925dfc12bda/requests-2.19.1-py2.py3-none-any.whl (91kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 4.9MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting six (from nltk)\n",
      "  Downloading https://files.pythonhosted.org/packages/67/4b/141a581104b1f6397bfa78ac9d43d8ad29a7ca43ea90a2d863fe3056e86a/six-1.11.0-py2.py3-none-any.whl\n",
      "Collecting urllib3<1.24,>=1.21.1 (from requests->torchtext)\n",
      "  Downloading https://files.pythonhosted.org/packages/bd/c9/6fdd990019071a4a32a5e7cb78a1d92c53851ef4f56f62a3486e6a7d8ffb/urllib3-1.23-py2.py3-none-any.whl (133kB)\n",
      "\u001b[K    100% |████████████████████████████████| 143kB 4.5MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting chardet<3.1.0,>=3.0.2 (from requests->torchtext)\n",
      "  Downloading https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl (133kB)\n",
      "\u001b[K    100% |████████████████████████████████| 143kB 4.5MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting certifi>=2017.4.17 (from requests->torchtext)\n",
      "  Downloading https://files.pythonhosted.org/packages/df/f7/04fee6ac349e915b82171f8e23cee63644d83663b34c539f7a09aed18f9e/certifi-2018.8.24-py2.py3-none-any.whl (147kB)\n",
      "\u001b[K    100% |████████████████████████████████| 153kB 4.3MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting idna<2.8,>=2.5 (from requests->torchtext)\n",
      "  Downloading https://files.pythonhosted.org/packages/4b/2a/0276479a4b3caeb8a8c1af2f8e4355746a97fab05a372e4a2c6a6b876165/idna-2.7-py2.py3-none-any.whl (58kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 6.4MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: torchtext, nltk\n",
      "  Running setup.py bdist_wheel for torchtext ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jeppe742/.cache/pip/wheels/42/a6/f4/b267328bde6bb680094a0c173e8e5627ccc99543abded97204\n",
      "  Running setup.py bdist_wheel for nltk ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jeppe742/.cache/pip/wheels/d1/ab/40/3bceea46922767e42986aef7606a600538ca80de6062dc266c\n",
      "Successfully built torchtext nltk\n",
      "Installing collected packages: tqdm, urllib3, chardet, certifi, idna, requests, torchtext, six, nltk\n",
      "Successfully installed certifi-2018.8.24 chardet-3.0.4 idna-2.7 nltk-3.3 requests-2.19.1 six-1.11.0 torchtext-0.2.3 tqdm-4.26.0 urllib3-1.23\n",
      "Collecting bokeh\n",
      "  Downloading https://files.pythonhosted.org/packages/07/1b/1bb751797f0bbbafc2642c629656ce158e7e7b7fb1110f449f7c320fb819/bokeh-0.13.0.tar.gz (16.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 16.0MB 92kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting six>=1.5.2 (from bokeh)\n",
      "  Using cached https://files.pythonhosted.org/packages/67/4b/141a581104b1f6397bfa78ac9d43d8ad29a7ca43ea90a2d863fe3056e86a/six-1.11.0-py2.py3-none-any.whl\n",
      "Collecting PyYAML>=3.10 (from bokeh)\n",
      "  Downloading https://files.pythonhosted.org/packages/9e/a3/1d13970c3f36777c583f136c136f804d70f500168edc1edea6daa7200769/PyYAML-3.13.tar.gz (270kB)\n",
      "\u001b[K    100% |████████████████████████████████| 276kB 4.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting python-dateutil>=2.1 (from bokeh)\n",
      "  Downloading https://files.pythonhosted.org/packages/cf/f5/af2b09c957ace60dcfac112b669c45c8c97e32f94aa8b56da4c6d1682825/python_dateutil-2.7.3-py2.py3-none-any.whl (211kB)\n",
      "\u001b[K    100% |████████████████████████████████| 215kB 4.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting Jinja2>=2.7 (from bokeh)\n",
      "  Downloading https://files.pythonhosted.org/packages/7f/ff/ae64bacdfc95f27a016a7bed8e8686763ba4d277a78ca76f32659220a731/Jinja2-2.10-py2.py3-none-any.whl (126kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 7.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.7.1 (from bokeh)\n",
      "  Downloading https://files.pythonhosted.org/packages/75/22/355e68c80802d6f488223788fbda75c1daab83c3ef609153676c1f17be5f/numpy-1.15.2-cp35-cp35m-manylinux1_x86_64.whl (13.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 13.8MB 106kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting packaging>=16.8 (from bokeh)\n",
      "  Downloading https://files.pythonhosted.org/packages/ad/c2/b500ea05d5f9f361a562f089fc91f77ed3b4783e13a08a3daf82069b1224/packaging-17.1-py2.py3-none-any.whl\n",
      "Collecting tornado>=4.3 (from bokeh)\n",
      "  Downloading https://files.pythonhosted.org/packages/e6/78/6e7b5af12c12bdf38ca9bfe863fcaf53dc10430a312d0324e76c1e5ca426/tornado-5.1.1.tar.gz (516kB)\n",
      "\u001b[K    100% |████████████████████████████████| 522kB 2.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting MarkupSafe>=0.23 (from Jinja2>=2.7->bokeh)\n",
      "  Downloading https://files.pythonhosted.org/packages/4d/de/32d741db316d8fdb7680822dd37001ef7a448255de9699ab4bfcbdf4172b/MarkupSafe-1.0.tar.gz\n",
      "Collecting pyparsing>=2.0.2 (from packaging>=16.8->bokeh)\n",
      "  Downloading https://files.pythonhosted.org/packages/42/47/e6d51aef3d0393f7d343592d63a73beee2a8d3d69c22b053e252c6cfacd5/pyparsing-2.2.1-py2.py3-none-any.whl (57kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 10.6MB/s ta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: bokeh, PyYAML, tornado, MarkupSafe\n",
      "  Running setup.py bdist_wheel for bokeh ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jeppe742/.cache/pip/wheels/05/3e/43/95ff0bde940a0a5d86ec13c22d2a4bddc97271cd788f441a63\n",
      "  Running setup.py bdist_wheel for PyYAML ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jeppe742/.cache/pip/wheels/ad/da/0c/74eb680767247273e2cf2723482cb9c924fe70af57c334513f\n",
      "  Running setup.py bdist_wheel for tornado ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jeppe742/.cache/pip/wheels/6d/e1/ce/f4ee2fa420cc6b940123c64992b81047816d0a9fad6b879325\n",
      "  Running setup.py bdist_wheel for MarkupSafe ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jeppe742/.cache/pip/wheels/33/56/20/ebe49a5c612fffe1c5a632146b16596f9e64676768661e4e46\n",
      "Successfully built bokeh PyYAML tornado MarkupSafe\n",
      "Installing collected packages: six, PyYAML, python-dateutil, MarkupSafe, Jinja2, numpy, pyparsing, packaging, tornado, bokeh\n",
      "Successfully installed Jinja2-2.10 MarkupSafe-1.0 PyYAML-3.13 bokeh-0.13.0 numpy-1.15.2 packaging-17.1 pyparsing-2.2.1 python-dateutil-2.7.3 six-1.11.0 tornado-5.1.1\n"
     ]
    }
   ],
   "source": [
    "#Uncomment and run the next lines if torchtext/bokeh/nltk isb't installed\n",
    "#!pip3 install --user torchtext nltk\n",
    "#!pip3 install bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"fbf0dfb6-4198-4038-837b-26e5f529aa20\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"fbf0dfb6-4198-4038-837b-26e5f529aa20\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"fbf0dfb6-4198-4038-837b-26e5f529aa20\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'fbf0dfb6-4198-4038-837b-26e5f529aa20' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.13.0.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"fbf0dfb6-4198-4038-837b-26e5f529aa20\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"fbf0dfb6-4198-4038-837b-26e5f529aa20\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"fbf0dfb6-4198-4038-837b-26e5f529aa20\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'fbf0dfb6-4198-4038-837b-26e5f529aa20' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.13.0.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"fbf0dfb6-4198-4038-837b-26e5f529aa20\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading trainDevTestTrees_PTB.zip\n",
      "extracting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/wiki.simple.vec: 293MB [00:38, 7.60MB/s]                              \n",
      "  0%|          | 0/111052 [00:00<?, ?it/s]Skipping token 111051 with 1-dimensional vector ['300']; likely a header\n",
      "100%|██████████| 111052/111052 [00:13<00:00, 8112.69it/s]\n"
     ]
    }
   ],
   "source": [
    "# RUN THIS LINE ASAP - Download the dataset while you read the exercise\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext.vocab import Vectors\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import Linear\n",
    "from torch.nn.functional import softmax, relu\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# we'll use the bokeh library to create beautiful plots\n",
    "# *_notebook functions are needed for correct use in jupyter\n",
    "from bokeh.plotting import figure, ColumnDataSource\n",
    "from bokeh.models import HoverTool\n",
    "from bokeh.io import output_notebook, show, push_notebook\n",
    "output_notebook()\n",
    "\n",
    "\n",
    "url = 'https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.simple.vec'\n",
    "\n",
    "# Following lines will be explained further below.\n",
    "# Run the cell and read the notebook further while the data gets downloaded\n",
    "TEXT = data.Field(sequential=True)\n",
    "LABEL = data.Field(sequential=False)\n",
    "train_set, validation_set, _ = datasets.SST.splits(TEXT,\n",
    "                                                   LABEL,\n",
    "                                                   fine_grained=False,\n",
    "                                                   train_subtrees=True,\n",
    "                                                   filter_pred=lambda ex: ex.label != 'neutral')\n",
    "TEXT.build_vocab(train_set, max_size=None, vectors=Vectors('wiki.simple.vec', url=url))\n",
    "LABEL.build_vocab(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Data\n",
    "\n",
    "In this lab we will introduce other ways of dealing with sequential data.\n",
    "As an example we will train a neural network to classify sequences of text as having either positive or negative sentiment.\n",
    "In the following we will exemplify methods on text given the same challenges as presented in [learning when to skim and when to read](https://einstein.ai/research/learning-when-to-skim-and-when-to-read).\n",
    "\n",
    "In this notebook we will show you \n",
    "* Some different ways to represent text.\n",
    "* Some PyTorch tools for working with text.\n",
    "* How to create a simple bag of words model for sentiment analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representing Text\n",
    "In previous labs we mainly considered data $x \\in \\mathrm{R}^d$, where $d$ is the feature space dimension.\n",
    "With time sequences our data can be represented as $x \\in \\mathrm{R}^{t \\, \\times \\, d}$, where $t$ is the sequence length. \n",
    "This emphasises sequence dependence and that the samples along the sequence are not independent and identically distributed (i.i.d.).\n",
    "We will model functions as $\\mathrm{R}^{t \\, \\times \\, d} \\rightarrow \\mathrm{R}^c$, where $c$ is the amount of classes in the output.\n",
    "\n",
    "\n",
    "There are several ways to represent sequences.\n",
    "With text the challenge is how to represent a word as the feature vector in $d$ dimensions, as it is required to represent text with decimal numbers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding over vocabulary\n",
    "\n",
    "One way to represent a fixed amount of words is by making a one-hot encoded vector, which consists of 0s in all cells with the exception of a single 1 in a cell used uniquely to identify each word.\n",
    "\n",
    "| vocabulary    | one-hot encoded vector   |\n",
    "| ------------- |--------------------------|\n",
    "| Paris         | $= [1, 0, 0, \\ldots, 0]$ |\n",
    "| Rome          | $= [0, 1, 0, \\ldots, 0]$ |\n",
    "| Copenhagen    | $= [0, 0, 1, \\ldots, 0]$ |\n",
    "\n",
    "Representing a large vocabulary with one-hot encodings often becomes inefficient because of the size of each sparse vector.\n",
    "To overcome this challenge it is common practice to truncate the vocabulary to contain the $k$ most used words and represent the rest with a special symbol, $\\mathtt{UNK}$, to define unknown/unimportant words.\n",
    "This often causes entities such as names to be represented with $\\mathtt{UNK}$.\n",
    "\n",
    "Consider the following text\n",
    "> I love the corny jokes in Spielberg's new movie.\n",
    "\n",
    "where an example result would be similar to\n",
    "> I love the corny jokes in $\\mathtt{UNK}$'s new movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings\n",
    "\n",
    "Word embeddings tries to tackle the intractability of one-hot encoded vectors, as $k$ is often in the range of 50k to 100k elements.\n",
    "Furthermore, one-hot encoding of vectors assumes orthogonality between all words, which makes it inept to incorporate relationships between words, e.g. `ran` and `run` should be related, where e.g. `awkward` and `space` should be far apart in the vector space.\n",
    "\n",
    "An embedding is defined as $\\mathrm{R}^d \\rightarrow \\mathrm{R}^{d'}$, where $d' \\ll d$.\n",
    "In practice this is often achieved by having a lookup table with $d'$-dimensional embeddings.\n",
    "\n",
    "For visualizations and more intuition check out [learning when to skim and when to read](https://einstein.ai/research/learning-when-to-skim-and-when-to-read)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words\n",
    "\n",
    "A simple way to model sequences of words is by averaging the word embeddings across the sequence dimension.\n",
    "This gives us a vector which contains information about each word, although completely disregarding the order of the words. Even though this might seem like a lossy approach to condense information it works surprisingly well.\n",
    "\n",
    "A bag of words model is represented as $\\mathrm{R}^{t \\, \\times \\, d'} \\rightarrow \\mathrm{R}^{d'}$, afterwards the representation can be used to do classification $\\mathrm{R}^{d'} \\rightarrow \\mathrm{R}^{c}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stanford sentiment treebank\n",
    "\n",
    "A great public dataset for sentiment analysis is the Stanford sentiment treebank (SST).\n",
    "The SST provides not only the class (positive, negative) for a sentence, but also each of its grammatical subphrases.\n",
    "We will not utilize any tree information.\n",
    "The original SST constitutes five classes: *very positive*, *positive*, *neutral*, *negative* and *very negative*.\n",
    "We consider the simpler task of binary classification where *very positive* is combined with *positive*, *very negative* is combined with *negative* and all *neutrals* are removed.\n",
    "\n",
    "### positive examples\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "  <ul>\n",
    "    <li>The actors are fantastic</li>\n",
    "    <li>A smart, witty follow-up.</li>\n",
    "    <li>You'll probably love it.</li>\n",
    "  </ul>\n",
    "</div>\n",
    "\n",
    "### negative examples\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "  <ul>\n",
    "    <li>Unflinchingly bleak and desperate.</li>\n",
    "    <li>An absurdist spider web.</li>\n",
    "    <li>Who cares?</li>\n",
    "  </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "def get_variable(x):\n",
    "    \"\"\" Converts tensors to cuda, if available. \"\"\"\n",
    "    if use_cuda:\n",
    "        return x.cuda()\n",
    "    return x\n",
    "\n",
    "def get_numpy(x):\n",
    "    \"\"\" Get numpy array for both cuda and not. \"\"\"\n",
    "    if use_cuda:\n",
    "        return x.cpu().data.numpy()\n",
    "    return x.data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loader - `torchtext`\n",
    "\n",
    "Creating data loaders for NLP is quite a hassle.\n",
    "[torchtext](https://github.com/pytorch/text/) is a convenient library with builtin functionality useful when working with text, e.g. building vocabularies and padding sequences to max length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `torchtext` - Fields and Dataset\n",
    "\n",
    "Our dataset must have a predefined structure, e.g. similar to a database table.\n",
    "\n",
    "- `torchtext.data.Field()` defines a column in our dataset table\n",
    "- `torchtext.datasets.SST` is a data loader for the Stanford Sentiment Treebank (SST) dataset\n",
    "- `torchtext.datasets.SST.split()` is a function to create train/validation/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we assume that all fields are sequential, i.e. there will be a sequence of data\n",
    "# however, the label field will not contain any sequence\n",
    "TEXT = data.Field(sequential=True)\n",
    "LABEL = data.Field(sequential=False)\n",
    "# create SST dataset splits\n",
    "# note, we remove samples with neutral labels\n",
    "train_set, validation_set, _ = datasets.SST.splits(TEXT,\n",
    "                                                   LABEL,\n",
    "                                                   fine_grained=False,\n",
    "                                                   train_subtrees=True,\n",
    "                                                   filter_pred=lambda ex: ex.label != 'neutral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('train_set.fields:', list(train_set.fields.keys()))\n",
    "print('validation_set.fields:', list(validation_set.fields.keys()))\n",
    "print()\n",
    "print('size of training set', len(train_set))\n",
    "print('size of validation set', len(validation_set))\n",
    "print()\n",
    "print('content of first training sample:')\n",
    "pprint(vars(train_set[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `torchtext` - Vocabulary\n",
    "\n",
    "For each `Field` we build a vocabulary to numericalize the symbols, e.g. `\"fun\" => 471`.\n",
    "When building a vocabulary we can attach embedding vectors, e.g. GloVe, FastText, etc.\n",
    "Many of these are already built into `torchtext`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the vocabularies\n",
    "url = 'https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.simple.vec'\n",
    "TEXT.build_vocab(train_set, max_size=None, vectors=Vectors('wiki.simple.vec', url=url))\n",
    "LABEL.build_vocab(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Text fields:')\n",
    "#print('keys of TEXT.vocab:', list(TEXT.vocab.__dict__.keys()))\n",
    "print(' size of vocabulary:', len(TEXT.vocab))\n",
    "print(\" vocabulary's embedding dimension:\", TEXT.vocab.vectors.size())\n",
    "print(' no. times the \"fun\" appear in the dataset:', TEXT.vocab.freqs['fun'])\n",
    "\n",
    "print('\\nLabel fields:')\n",
    "#print('keys of LABEL.vocab:', list(LABEL.vocab.__dict__.keys()))\n",
    "print(\" list of vocabulary (int-to-str):\", LABEL.vocab.itos)\n",
    "print(\" list of vocabulary (str-to-int):\", dict(LABEL.vocab.stoi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `torchtext` - Iterator over datasets\n",
    "\n",
    "`torchtext.data.Iterator` is a class which can be used to create iterators.\n",
    "These iterators have various useful functionality, e.g. to shuffle at every epoch, or to generate data endlessly.\n",
    "It is useful to be able to generate endless batches of training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make iterator for splits\n",
    "# device gives a CUDA enabled device (-1 disables it)\n",
    "train_iter, val_iter, _ = data.BucketIterator.splits((train_set, validation_set, _),\n",
    "                                                     batch_size=128, \n",
    "                                                     device=0 if use_cuda else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print batch information\n",
    "batch = next(iter(train_iter))\n",
    "print(\"dimension of batch's text:\", batch.text.size())\n",
    "print(\"first sequence in text:\", batch.text[:,0])\n",
    "print(\"correct label index:\", batch.label[0])\n",
    "print(\"the actual label:\", LABEL.vocab.itos[get_numpy(batch.label[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Bag of Words Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of embeddings\n",
    "embedding_dim = TEXT.vocab.vectors.size()[1]\n",
    "num_embeddings = TEXT.vocab.vectors.size()[0]\n",
    "num_classes = len(LABEL.vocab.itos)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.embeddings = nn.Embedding(num_embeddings, embedding_dim)\n",
    "        # use pretrained embeddings\n",
    "        self.embeddings.weight.data.copy_(TEXT.vocab.vectors)\n",
    "        \n",
    "        # add hidden layers\n",
    "        # YOUR CODE HERE!\n",
    "#         self.l_1 = Linear(in_features=embedding_dim,\n",
    "#                           out_features=30,\n",
    "#                           bias=True)\n",
    "#         self.l_2 = Linear(in_features=30,\n",
    "#                           out_features=30,\n",
    "#                           bias=True)\n",
    "        \n",
    "        # output layer\n",
    "        self.l_out = Linear(in_features=embedding_dim,\n",
    "                            out_features=num_classes,\n",
    "                            bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = {}\n",
    "        # get embeddings\n",
    "        x = self.embeddings(x)\n",
    "        \n",
    "        # mean embeddings, this is the bag of words trick\n",
    "        out['bow'] = x = torch.mean(x, dim=0)\n",
    "        \n",
    "        # add hidden layers\n",
    "        # YOUR CODE HERE!\n",
    "#         out['l1_activations'] = x = relu(self.l_1(x))\n",
    "#         out['l2_activations'] = x = relu(self.l_2(x))\n",
    "\n",
    "\n",
    "        # Softmax\n",
    "        out['out'] = softmax(self.l_out(x), dim=1)\n",
    "        return out\n",
    "\n",
    "net = Net()\n",
    "if use_cuda:\n",
    "    net.cuda()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "def accuracy(ys, ts):\n",
    "    # making a one-hot encoded vector of correct (1) and incorrect (0) predictions\n",
    "    correct_prediction = torch.eq(torch.max(ys, 1)[1], ts)\n",
    "    # averaging the one-hot encoded vector\n",
    "    return torch.mean(correct_prediction.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_sentences(batch):\n",
    "    \"\"\"    \n",
    "    Parameters\n",
    "    ----------\n",
    "    batch: torchtext.data.batch.Batch\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    [str]\n",
    "    \"\"\"\n",
    "    return [\" \".join([TEXT.vocab.itos[elm] \n",
    "                      for elm in get_numpy(batch.text[:,i])])\n",
    "            for i in range(batch.text.size()[1])]\n",
    "\n",
    "def get_labels(batch):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    batch: torchtext.data.batch.Batch\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    [str]\n",
    "    \"\"\"\n",
    "    return [LABEL.vocab.itos[get_numpy(batch.label[i])] for i in range(len(batch.label))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to project our hidden embeddings to a visualizable space\n",
    "tsne = TSNE(perplexity=10.0, learning_rate=5.0, n_iter=2000)\n",
    "\n",
    "# index for each label\n",
    "colormap = {1: 'DodgerBlue', 2: 'FireBrick'}\n",
    "\n",
    "# create a tmp source to be updated later\n",
    "validation_set_size = len(validation_set)\n",
    "source = ColumnDataSource(data={'x': np.random.randn(validation_set_size),\n",
    "                                'y': np.random.randn(validation_set_size),\n",
    "                                'colors': ['green']*validation_set_size,\n",
    "                                'sentences': [\"tmp\"]*validation_set_size,\n",
    "                                'labels': [\"unk\"]*validation_set_size})\n",
    "\n",
    "# instance to define hover logic in plot\n",
    "hover = HoverTool(tooltips=[(\"Sentence\", \"@sentences\"), (\"Label\", \"@labels\")])\n",
    "\n",
    "# set up the bokeh figure for later visualizations\n",
    "p = figure(tools=[hover])\n",
    "p.circle(x='x', y='y', fill_color='colors', size=5, line_color=None, source=source)\n",
    "\n",
    "def update_plot(meta, layer, handle):\n",
    "    \"\"\" Update existing plot\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    meta: dict\n",
    "    layer: str\n",
    "    \"\"\"\n",
    "    tsne_acts = tsne.fit_transform(meta[layer])\n",
    "    source.data['x'] = tsne_acts[:,0]\n",
    "    source.data['y'] = tsne_acts[:,1]\n",
    "    source.data['colors'] = [colormap[l] for l in meta['label_idx']]\n",
    "    \n",
    "    source.data['sentences'] = meta['sentences']\n",
    "    source.data['labels'] = meta['labels']\n",
    "    \n",
    "    # this updates the given plot\n",
    "    push_notebook(handle=handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the bag of words model\n",
    "\n",
    "**Warning** this might take a while on CPU.\n",
    "Go get a cop of coffe, and enjoy the visualizations.\n",
    "\n",
    "Notice that each data point in the plot corresponds to an entire sentence in the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_iter = 3000\n",
    "eval_every = 1000\n",
    "log_every = 200\n",
    "\n",
    "# will be updated while iterating\n",
    "tsne_plot = show(p, notebook_handle=True)\n",
    "\n",
    "train_loss, train_accs = [], []\n",
    "\n",
    "net.train()\n",
    "for i, batch in enumerate(train_iter):\n",
    "    if i % eval_every == 0:\n",
    "        net.eval()\n",
    "        val_losses, val_accs, val_lengths = 0, 0, 0\n",
    "        val_meta = {'label_idx': [], 'sentences': [], 'labels': []}\n",
    "        for val_batch in val_iter:\n",
    "            output = net(val_batch.text)\n",
    "            # batches sizes might vary, which is why we cannot just mean the batch's loss\n",
    "            # we multiply the loss and accuracies with the batch's size,\n",
    "            # to later divide by the total size\n",
    "            val_losses += criterion(output['out'], val_batch.label) * val_batch.batch_size\n",
    "            val_accs += accuracy(output['out'], val_batch.label) * val_batch.batch_size\n",
    "            val_lengths += val_batch.batch_size\n",
    "            \n",
    "            for key, _val in output.items():\n",
    "                if key not in val_meta:\n",
    "                    val_meta[key] = []\n",
    "                val_meta[key].append(get_numpy(_val)) \n",
    "            val_meta['label_idx'].append(get_numpy(val_batch.label))\n",
    "            val_meta['sentences'].append(construct_sentences(val_batch))\n",
    "            val_meta['labels'].append(get_labels(val_batch))\n",
    "        \n",
    "        for key, _val in val_meta.items():\n",
    "            val_meta[key] = np.concatenate(_val)\n",
    "        \n",
    "        # divide by the total accumulated batch sizes\n",
    "        val_losses /= val_lengths\n",
    "        val_accs /= val_lengths\n",
    "        \n",
    "        print(\"valid, it: {} loss: {:.2f} accs: {:.2f}\\n\".format(i, get_numpy(val_losses), get_numpy(val_accs)))\n",
    "        update_plot(val_meta, 'bow', tsne_plot)\n",
    "        \n",
    "        net.train()\n",
    "    \n",
    "    output = net(batch.text)\n",
    "    batch_loss = criterion(output['out'], batch.label)\n",
    "    \n",
    "    train_loss.append(get_numpy(batch_loss))\n",
    "    train_accs.append(get_numpy(accuracy(output['out'], batch.label)))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    batch_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % log_every == 0:        \n",
    "        print(\"train, it: {} loss: {:.2f} accs: {:.2f}\".format(i, \n",
    "                                                               np.mean(train_loss), \n",
    "                                                               np.mean(train_accs)))\n",
    "        # reset\n",
    "        train_loss, train_accs = [], []\n",
    "        \n",
    "    if max_iter < i:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: add hidden layer\n",
    "\n",
    "- add one hidden layer to the bag of words (BoW) model\n",
    "  - plot the hidden layer's activations instead of the BoW representation\n",
    "- add a second hidden layer\n",
    "  - try and plot the activations of the second hidden layer\n",
    "\n",
    "Notice any difference in the plots?\n",
    "Describe what you see.\n",
    "Hover over the data points."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
